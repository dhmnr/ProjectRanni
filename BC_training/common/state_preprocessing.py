"""State preprocessing for behavior cloning models.

Transforms raw game state into normalized/processed features.
Used by all models that consume state data.

Output structure:
    - continuous: [B, 10] float32 - resources (4) + distances (6)
    - hero_anim_idx: [B] int32 - index for embedding lookup
    - npc_anim_idx: [B] int32 - index for embedding lookup
    - anim_onset_encoding: [B, encoding_dim] float32 - sinusoidal encoding of frames since anim onset
"""

import numpy as np
from typing import Dict, Optional, Union
from pathlib import Path
import json
import logging

logger = logging.getLogger(__name__)


def sinusoidal_encoding(positions: np.ndarray, dim: int = 16, max_period: float = 60.0) -> np.ndarray:
    """Encode positions using sinusoidal encoding (like Transformer positional encoding).

    This encoding allows the model to learn relative timing patterns, where nearby
    positions have similar encodings and the model can easily learn "around frame 8-10".

    Args:
        positions: Array of positions/frame counts, shape [B] or [B, T]
        dim: Dimension of encoding (must be even)
        max_period: Maximum period for the highest frequency component.
                   For animation timing, 60 frames (~2 seconds at 30fps) is reasonable.

    Returns:
        Encoded positions, shape [B, dim] or [B, T, dim]
    """
    assert dim % 2 == 0, "Encoding dimension must be even"

    # Ensure positions is float
    positions = np.asarray(positions, dtype=np.float32)
    original_shape = positions.shape

    # Flatten for computation
    positions_flat = positions.reshape(-1)

    # Create frequency bands (exponentially spaced)
    # Higher frequencies capture fine-grained timing, lower frequencies capture coarse patterns
    half_dim = dim // 2
    freqs = np.exp(np.arange(half_dim) * (-np.log(max_period) / half_dim))

    # Compute angles: [num_positions, half_dim]
    angles = positions_flat[:, np.newaxis] * freqs[np.newaxis, :]

    # Interleave sin and cos: [num_positions, dim]
    encoding = np.zeros((len(positions_flat), dim), dtype=np.float32)
    encoding[:, 0::2] = np.sin(angles)
    encoding[:, 1::2] = np.cos(angles)

    # Reshape to match input
    output_shape = original_shape + (dim,)
    return encoding.reshape(output_shape)


# State attribute indices (from zarr dataset)
STATE_INDICES = {
    'HeroHp': 0,
    'HeroMaxHp': 1,
    'HeroSp': 2,
    'HeroMaxSp': 3,
    'HeroFp': 4,
    'HeroMaxFp': 5,
    'HeroGlobalPosX': 6,
    'HeroGlobalPosY': 7,
    'HeroGlobalPosZ': 8,
    'HeroAngle': 9,
    'HeroAnimId': 10,
    'NpcHp': 11,
    'NpcMaxHp': 12,
    'NpcId': 13,
    'NpcGlobalPosX': 14,
    'NpcGlobalPosY': 15,
    'NpcGlobalPosZ': 16,
    'NpcGlobalPosAngle': 17,
    'NpcAnimId': 18,
}

# NPC Y coordinate offset (discovered empirically - 8 bits)
NPC_Y_OFFSET = -8.0


class StatePreprocessor:
    """Preprocesses raw game state into normalized features + animation indices.
    
    Features:
    - Normalizes HP, SP, FP to [0, 1] using their max values
    - Computes relative position features (distance, direction to NPC)
    - Maps animation IDs to embedding indices
    - Drops useless columns: HeroAngle, NpcAngle, NpcId
    
    Output:
        Dict with:
        - 'continuous': [B, 10] float32 - resources + distances
        - 'hero_anim_idx': [B] int32 - embedding index
        - 'npc_anim_idx': [B] int32 - embedding index
    """
    
    def __init__(
        self,
        normalize_resources: bool = True,
        compute_distances: bool = True,
        anim_mappings_path: Optional[str] = None,
    ):
        """Initialize preprocessor.
        
        Args:
            normalize_resources: Normalize HP/SP/FP by max values
            compute_distances: Compute distance features instead of raw coords
            anim_mappings_path: Path to JSON file with animation ID mappings
                               (generated by analyze_dataset.py)
        """
        self.normalize_resources = normalize_resources
        self.compute_distances = compute_distances
        
        # Load animation ID mappings
        if anim_mappings_path:
            self._load_anim_mappings(anim_mappings_path)
        else:
            # Default: no embedding, pass raw IDs (not recommended)
            self.hero_id_to_idx = None
            self.npc_id_to_idx = None
            self.hero_vocab_size = 0
            self.npc_vocab_size = 0
        
        logger.info(f"StatePreprocessor initialized:")
        logger.info(f"  normalize_resources: {normalize_resources}")
        logger.info(f"  compute_distances: {compute_distances}")
        logger.info(f"  continuous_dim: {self.continuous_dim}")
        logger.info(f"  hero_vocab_size: {self.hero_vocab_size}")
        logger.info(f"  npc_vocab_size: {self.npc_vocab_size}")
    
    def _load_anim_mappings(self, path: str):
        """Load animation ID to index mappings from JSON file."""
        with open(path, 'r') as f:
            mappings = json.load(f)
        
        # Convert string keys back to int (JSON limitation)
        self.hero_id_to_idx = {int(k): v for k, v in mappings['hero_id_to_idx'].items()}
        self.npc_id_to_idx = {int(k): v for k, v in mappings['npc_id_to_idx'].items()}
        
        # Add 1 for UNK token at index 0
        self.hero_vocab_size = mappings['hero_anim_vocab_size'] + 1
        self.npc_vocab_size = mappings['npc_anim_vocab_size'] + 1
        
        # Shift all indices by 1 to reserve 0 for UNK
        self.hero_id_to_idx = {k: v + 1 for k, v in self.hero_id_to_idx.items()}
        self.npc_id_to_idx = {k: v + 1 for k, v in self.npc_id_to_idx.items()}
        
        logger.info(f"Loaded animation mappings from {path}")
        logger.info(f"  Hero: {len(self.hero_id_to_idx)} IDs -> vocab_size {self.hero_vocab_size}")
        logger.info(f"  NPC: {len(self.npc_id_to_idx)} IDs -> vocab_size {self.npc_vocab_size}")
    
    def _map_anim_id(self, raw_id: int, id_to_idx: dict) -> int:
        """Map raw animation ID to embedding index. Returns 0 (UNK) for unknown IDs."""
        return id_to_idx.get(int(raw_id), 0)
    
    def __call__(self, state: np.ndarray) -> Dict[str, np.ndarray]:
        """Process state array.
        
        Args:
            state: Raw state array [B, 19] or [19]
            
        Returns:
            Dict with 'continuous', 'hero_anim_idx', 'npc_anim_idx'
        """
        return self.process(state)
    
    def process(self, state: np.ndarray) -> Dict[str, np.ndarray]:
        """Process state array.
        
        Args:
            state: Raw state array [B, 19] or [19]
            
        Returns:
            Dict with 'continuous', 'hero_anim_idx', 'npc_anim_idx'
        """
        # Handle both batched and single samples
        single_sample = state.ndim == 1
        if single_sample:
            state = state[np.newaxis, :]
        
        batch_size = state.shape[0]
        
        # === Extract values from original indices ===
        # Resources
        hero_hp = state[:, STATE_INDICES['HeroHp']]
        hero_max_hp = np.maximum(state[:, STATE_INDICES['HeroMaxHp']], 1.0)
        hero_sp = state[:, STATE_INDICES['HeroSp']]
        hero_max_sp = np.maximum(state[:, STATE_INDICES['HeroMaxSp']], 1.0)
        hero_fp = state[:, STATE_INDICES['HeroFp']]
        hero_max_fp = np.maximum(state[:, STATE_INDICES['HeroMaxFp']], 1.0)
        npc_hp = state[:, STATE_INDICES['NpcHp']]
        npc_max_hp = np.maximum(state[:, STATE_INDICES['NpcMaxHp']], 1.0)
        
        # Coordinates
        hero_x = state[:, STATE_INDICES['HeroGlobalPosX']]
        hero_y = state[:, STATE_INDICES['HeroGlobalPosY']]
        hero_z = state[:, STATE_INDICES['HeroGlobalPosZ']]
        npc_x = state[:, STATE_INDICES['NpcGlobalPosX']]
        npc_y = state[:, STATE_INDICES['NpcGlobalPosY']] + NPC_Y_OFFSET
        npc_z = state[:, STATE_INDICES['NpcGlobalPosZ']]
        
        # Animation IDs (raw)
        hero_anim_raw = state[:, STATE_INDICES['HeroAnimId']].astype(np.int64)
        npc_anim_raw = state[:, STATE_INDICES['NpcAnimId']].astype(np.int64)
        
        # === Build continuous features ===
        features = []
        
        # Resources (4 features)
        if self.normalize_resources:
            features.extend([
                hero_hp / hero_max_hp,
                hero_sp / hero_max_sp,
                hero_fp / hero_max_fp,
                npc_hp / npc_max_hp,
            ])
        else:
            features.extend([
                hero_hp, hero_max_hp,
                hero_sp, hero_max_sp,
                hero_fp, hero_max_fp,
                npc_hp, npc_max_hp,
            ])
        
        # Coordinates (6 features)
        if self.compute_distances:
            rel_x = npc_x - hero_x
            rel_y = npc_y - hero_y
            rel_z = npc_z - hero_z
            
            distance_xy = np.sqrt(rel_x**2 + rel_y**2)
            distance_3d = np.sqrt(rel_x**2 + rel_y**2 + rel_z**2)
            angle_to_npc = np.arctan2(rel_y, rel_x)
            
            features.extend([
                distance_xy,
                distance_3d,
                rel_x,
                rel_y,
                rel_z,
                angle_to_npc,
            ])
        else:
            features.extend([
                hero_x, hero_y, hero_z,
                npc_x, npc_y, npc_z,
            ])
        
        continuous = np.stack(features, axis=1).astype(np.float32)
        
        # === Map animation IDs to embedding indices ===
        if self.hero_id_to_idx is not None:
            hero_anim_idx = np.array([
                self._map_anim_id(id_, self.hero_id_to_idx) for id_ in hero_anim_raw
            ], dtype=np.int32)
            npc_anim_idx = np.array([
                self._map_anim_id(id_, self.npc_id_to_idx) for id_ in npc_anim_raw
            ], dtype=np.int32)
        else:
            # Fallback: use raw IDs (not recommended - sparse indices)
            hero_anim_idx = hero_anim_raw.astype(np.int32)
            npc_anim_idx = npc_anim_raw.astype(np.int32)
        
        # Handle single sample output
        if single_sample:
            continuous = continuous[0]
            hero_anim_idx = hero_anim_idx[0]
            npc_anim_idx = npc_anim_idx[0]
        
        return {
            'continuous': continuous,
            'hero_anim_idx': hero_anim_idx,
            'npc_anim_idx': npc_anim_idx,
        }
    
    @property
    def continuous_dim(self) -> int:
        """Get number of continuous features."""
        if self.normalize_resources:
            return 4 + 6  # 4 resources + 6 coords/distances
        else:
            return 8 + 6  # 8 raw resources + 6 coords/distances
    
    @property
    def output_dim(self) -> int:
        """Deprecated - use continuous_dim instead."""
        return self.continuous_dim
    
    def get_feature_names(self) -> dict:
        """Get names of output features for debugging/logging."""
        continuous_names = []
        
        if self.normalize_resources:
            continuous_names.extend(['hero_hp_ratio', 'hero_sp_ratio', 'hero_fp_ratio', 'npc_hp_ratio'])
        else:
            continuous_names.extend(['hero_hp', 'hero_max_hp', 'hero_sp', 'hero_max_sp',
                                    'hero_fp', 'hero_max_fp', 'npc_hp', 'npc_max_hp'])
        
        if self.compute_distances:
            continuous_names.extend(['distance_xy', 'distance_3d', 'rel_x', 'rel_y', 'rel_z', 'angle_to_npc'])
        else:
            continuous_names.extend(['hero_x', 'hero_y', 'hero_z', 'npc_x', 'npc_y', 'npc_z'])
        
        return {
            'continuous': continuous_names,
            'categorical': ['hero_anim_idx', 'npc_anim_idx'],
        }


def create_preprocessor(config: Optional[Dict] = None) -> StatePreprocessor:
    """Factory function to create preprocessor from config.
    
    Args:
        config: Config dict with 'state_preprocessing' and 'dataset' sections
        
    Returns:
        StatePreprocessor instance
    """
    if config is None:
        config = {}
    
    preprocess_config = config.get('state_preprocessing', {})
    dataset_config = config.get('dataset', {})
    
    # Look for mappings file next to dataset
    anim_mappings_path = preprocess_config.get('anim_mappings_path')
    if anim_mappings_path is None and 'path' in dataset_config:
        # Try to find mappings file in dataset directory
        dataset_path = Path(dataset_config['path'])
        default_path = dataset_path.parent / 'anim_id_mappings.json'
        if default_path.exists():
            anim_mappings_path = str(default_path)
            logger.info(f"Found animation mappings at {anim_mappings_path}")
    
    return StatePreprocessor(
        normalize_resources=preprocess_config.get('normalize_resources', True),
        compute_distances=preprocess_config.get('compute_distances', True),
        anim_mappings_path=anim_mappings_path,
    )
