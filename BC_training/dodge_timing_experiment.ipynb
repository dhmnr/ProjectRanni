{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dodge Timing Experiment\n",
    "\n",
    "Can a pure CNN distinguish frames where dodge is about to happen vs not?\n",
    "\n",
    "- **Positive samples**: 16 frames leading up to a dodge\n",
    "- **Negative samples**: 16 frames from random points (no dodge within ±X frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Config\n",
    "DATASET_PATH = '../dataset/margit_100_256x144.zarr'\n",
    "NUM_FRAMES = 16  # Frames to stack\n",
    "DODGE_IDX = 4  # dodge_roll/dash action index\n",
    "NEGATIVE_BUFFER = 20  # Negative samples must be at least this far from any dodge\n",
    "TRAIN_RATIO = 0.8\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 episodes\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "zarr_root = zarr.open(DATASET_PATH, mode='r')\n",
    "episodes = sorted([k for k in zarr_root.keys() if k.startswith('episode_')])\n",
    "print(f\"Loaded {len(episodes)} episodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning episodes:  13%|█▎        | 13/100 [00:00<00:00, 318.38it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m num_frames \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Find all dodge frames\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m dodge_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDODGE_IDX\u001b[49m\u001b[43m]\u001b[49m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Find dodge onsets (first frame of dodge press)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m dodge_onset_frames \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"
     ]
    }
   ],
   "source": [
    "# Extract positive and negative samples\n",
    "positive_samples = []  # (episode, end_frame) - frames [end_frame-15:end_frame+1] lead to dodge\n",
    "negative_candidates = []  # (episode, end_frame) - no dodge nearby\n",
    "\n",
    "for ep_name in tqdm(episodes, desc=\"Scanning episodes\"):\n",
    "    ep = zarr_root[ep_name]\n",
    "    actions = ep['actions'][:]\n",
    "    num_frames = actions.shape[0]\n",
    "    \n",
    "    # Find all dodge frames\n",
    "    dodge_frames = set(np.where(actions[:, DODGE_IDX])[0])\n",
    "    \n",
    "    # Find dodge onsets (first frame of dodge press)\n",
    "    dodge_onset_frames = []\n",
    "    prev_dodge = False\n",
    "    for i in range(num_frames):\n",
    "        curr_dodge = actions[i, DODGE_IDX]\n",
    "        if curr_dodge and not prev_dodge:\n",
    "            dodge_onset_frames.append(i)\n",
    "        prev_dodge = curr_dodge\n",
    "    \n",
    "    # Positive samples: 16 frames ending at dodge onset\n",
    "    for onset in dodge_onset_frames:\n",
    "        if onset >= NUM_FRAMES - 1:  # Need 16 frames before\n",
    "            positive_samples.append((ep_name, onset))\n",
    "    \n",
    "    # Negative candidates: frames far from any dodge\n",
    "    for i in range(NUM_FRAMES - 1, num_frames):\n",
    "        # Check if any dodge within buffer\n",
    "        nearby_dodge = False\n",
    "        for d in range(i - NEGATIVE_BUFFER, i + NEGATIVE_BUFFER + 1):\n",
    "            if d in dodge_frames:\n",
    "                nearby_dodge = True\n",
    "                break\n",
    "        if not nearby_dodge:\n",
    "            negative_candidates.append((ep_name, i))\n",
    "\n",
    "print(f\"Positive samples (dodge onsets): {len(positive_samples)}\")\n",
    "print(f\"Negative candidates: {len(negative_candidates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance dataset - sample negatives to match positives\n",
    "np.random.seed(42)\n",
    "num_negatives = len(positive_samples)  # 1:1 ratio\n",
    "negative_samples = [negative_candidates[i] for i in \n",
    "                    np.random.choice(len(negative_candidates), size=num_negatives, replace=False)]\n",
    "\n",
    "print(f\"Using {len(positive_samples)} positive, {len(negative_samples)} negative samples\")\n",
    "\n",
    "# Create labels\n",
    "all_samples = positive_samples + negative_samples\n",
    "all_labels = [1] * len(positive_samples) + [0] * len(negative_samples)\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(len(all_samples))\n",
    "all_samples = [all_samples[i] for i in indices]\n",
    "all_labels = [all_labels[i] for i in indices]\n",
    "\n",
    "# Train/val split\n",
    "split_idx = int(len(all_samples) * TRAIN_RATIO)\n",
    "train_samples, val_samples = all_samples[:split_idx], all_samples[split_idx:]\n",
    "train_labels, val_labels = all_labels[:split_idx], all_labels[split_idx:]\n",
    "\n",
    "print(f\"Train: {len(train_samples)}, Val: {len(val_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frame_stack(zarr_root, ep_name, end_frame, num_frames=16):\n",
    "    \"\"\"Load stack of frames ending at end_frame.\"\"\"\n",
    "    ep = zarr_root[ep_name]\n",
    "    start_frame = end_frame - num_frames + 1\n",
    "    frames = ep['frames'][start_frame:end_frame + 1]  # [T, C, H, W]\n",
    "    # Normalize to [0, 1]\n",
    "    frames = frames.astype(np.float32) / 255.0\n",
    "    return frames\n",
    "\n",
    "def create_batch(zarr_root, samples, labels, batch_indices):\n",
    "    \"\"\"Create a batch of frame stacks and labels.\"\"\"\n",
    "    batch_frames = []\n",
    "    batch_labels = []\n",
    "    for i in batch_indices:\n",
    "        ep_name, end_frame = samples[i]\n",
    "        frames = load_frame_stack(zarr_root, ep_name, end_frame, NUM_FRAMES)\n",
    "        batch_frames.append(frames)\n",
    "        batch_labels.append(labels[i])\n",
    "    return np.stack(batch_frames), np.array(batch_labels, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN for binary classification\n",
    "class DodgeTimingCNN(nn.Module):\n",
    "    \"\"\"CNN to predict if dodge is imminent from frame stack.\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, training: bool = True):\n",
    "        # x: [B, T, C, H, W]\n",
    "        B, T, C, H, W = x.shape\n",
    "        \n",
    "        # Stack frames as channels: [B, T*C, H, W]\n",
    "        x = x.reshape(B, T * C, H, W)\n",
    "        \n",
    "        # Transpose to [B, H, W, C] for Flax conv\n",
    "        x = jnp.transpose(x, (0, 2, 3, 1))\n",
    "        \n",
    "        # Conv layers\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), strides=(2, 2))(x)\n",
    "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), strides=(2, 2))(x)\n",
    "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        x = nn.Conv(features=128, kernel_size=(3, 3), strides=(2, 2))(x)\n",
    "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        x = nn.Conv(features=256, kernel_size=(3, 3), strides=(2, 2))(x)\n",
    "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = jnp.mean(x, axis=(1, 2))  # [B, 256]\n",
    "        \n",
    "        # Dense layers\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(rate=0.5, deterministic=not training)(x)\n",
    "        \n",
    "        # Output: single logit for binary classification\n",
    "        x = nn.Dense(features=1)(x)\n",
    "        return x.squeeze(-1)  # [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = DodgeTimingCNN()\n",
    "rng = jax.random.PRNGKey(42)\n",
    "init_rng, dropout_rng = jax.random.split(rng)\n",
    "\n",
    "# Dummy input for init\n",
    "dummy_input = jnp.ones((1, NUM_FRAMES, 3, 144, 256))\n",
    "variables = model.init({'params': init_rng, 'dropout': dropout_rng}, dummy_input, training=False)\n",
    "\n",
    "# Count parameters\n",
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(variables['params']))\n",
    "print(f\"Model parameters: {param_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training state\n",
    "class TrainState(train_state.TrainState):\n",
    "    batch_stats: dict\n",
    "\n",
    "tx = optax.adam(LEARNING_RATE)\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=variables['params'],\n",
    "    tx=tx,\n",
    "    batch_stats=variables['batch_stats'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and train step\n",
    "@jax.jit\n",
    "def train_step(state, batch, labels, rng):\n",
    "    def loss_fn(params):\n",
    "        logits, updates = state.apply_fn(\n",
    "            {'params': params, 'batch_stats': state.batch_stats},\n",
    "            batch, training=True,\n",
    "            mutable=['batch_stats'],\n",
    "            rngs={'dropout': rng}\n",
    "        )\n",
    "        loss = optax.sigmoid_binary_cross_entropy(logits, labels).mean()\n",
    "        return loss, (logits, updates)\n",
    "    \n",
    "    (loss, (logits, updates)), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    state = state.replace(batch_stats=updates['batch_stats'])\n",
    "    \n",
    "    preds = jax.nn.sigmoid(logits) > 0.5\n",
    "    acc = (preds == labels).mean()\n",
    "    return state, loss, acc\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, batch, labels):\n",
    "    logits = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        batch, training=False\n",
    "    )\n",
    "    loss = optax.sigmoid_binary_cross_entropy(logits, labels).mean()\n",
    "    preds = jax.nn.sigmoid(logits) > 0.5\n",
    "    acc = (preds == labels).mean()\n",
    "    probs = jax.nn.sigmoid(logits)\n",
    "    return loss, acc, preds, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Shuffle training data\n",
    "    perm = np.random.permutation(len(train_samples))\n",
    "    \n",
    "    # Training\n",
    "    epoch_losses, epoch_accs = [], []\n",
    "    for i in tqdm(range(0, len(train_samples), BATCH_SIZE), desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", leave=False):\n",
    "        batch_idx = perm[i:i+BATCH_SIZE]\n",
    "        if len(batch_idx) < BATCH_SIZE:\n",
    "            continue\n",
    "        \n",
    "        batch, labels = create_batch(zarr_root, train_samples, train_labels, batch_idx)\n",
    "        batch = jnp.array(batch)\n",
    "        labels = jnp.array(labels)\n",
    "        \n",
    "        rng, step_rng = jax.random.split(rng)\n",
    "        state, loss, acc = train_step(state, batch, labels, step_rng)\n",
    "        epoch_losses.append(float(loss))\n",
    "        epoch_accs.append(float(acc))\n",
    "    \n",
    "    train_loss = np.mean(epoch_losses)\n",
    "    train_acc = np.mean(epoch_accs)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Validation\n",
    "    val_epoch_losses, val_epoch_accs = [], []\n",
    "    for i in range(0, len(val_samples), BATCH_SIZE):\n",
    "        batch_idx = list(range(i, min(i+BATCH_SIZE, len(val_samples))))\n",
    "        if len(batch_idx) < 2:\n",
    "            continue\n",
    "        batch, labels = create_batch(zarr_root, val_samples, val_labels, batch_idx)\n",
    "        batch = jnp.array(batch)\n",
    "        labels = jnp.array(labels)\n",
    "        \n",
    "        loss, acc, _, _ = eval_step(state, batch, labels)\n",
    "        val_epoch_losses.append(float(loss))\n",
    "        val_epoch_accs.append(float(acc))\n",
    "    \n",
    "    val_loss = np.mean(val_epoch_losses)\n",
    "    val_acc = np.mean(val_epoch_accs)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={train_acc:.4f} | Val Loss={val_loss:.4f}, Acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(train_losses, label='Train')\n",
    "axes[0].plot(val_losses, label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss Curve')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(train_accs, label='Train')\n",
    "axes[1].plot(val_accs, label='Val')\n",
    "axes[1].axhline(y=0.5, color='gray', linestyle='--', label='Random')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy Curve')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest Val Accuracy: {max(val_accs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full validation evaluation\n",
    "all_preds, all_probs, all_true = [], [], []\n",
    "\n",
    "for i in range(0, len(val_samples), BATCH_SIZE):\n",
    "    batch_idx = list(range(i, min(i+BATCH_SIZE, len(val_samples))))\n",
    "    if len(batch_idx) < 1:\n",
    "        continue\n",
    "    batch, labels = create_batch(zarr_root, val_samples, val_labels, batch_idx)\n",
    "    batch = jnp.array(batch)\n",
    "    labels = jnp.array(labels)\n",
    "    \n",
    "    _, _, preds, probs = eval_step(state, batch, labels)\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_probs.extend(probs.tolist())\n",
    "    all_true.extend(labels.tolist())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "all_true = np.array(all_true)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_true, all_preds, target_names=['No Dodge', 'Dodge']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_true, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Dodge', 'Dodge'],\n",
    "            yticklabels=['No Dodge', 'Dodge'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.hist(all_probs[all_true == 0], bins=50, alpha=0.5, label='No Dodge (True)', color='blue')\n",
    "ax.hist(all_probs[all_true == 1], bins=50, alpha=0.5, label='Dodge (True)', color='red')\n",
    "ax.axvline(x=0.5, color='black', linestyle='--', label='Threshold')\n",
    "ax.set_xlabel('Predicted Probability of Dodge')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Probability Distribution by True Label')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== CONCLUSION ===\")\n",
    "if max(val_accs) > 0.65:\n",
    "    print(f\"Model achieves {max(val_accs)*100:.1f}% accuracy - VISUAL SIGNAL EXISTS!\")\n",
    "    print(\"The CNN can distinguish pre-dodge frames from non-dodge frames.\")\n",
    "    print(\"Issue is likely in how temporal_cnn uses this signal, not the signal itself.\")\n",
    "elif max(val_accs) > 0.55:\n",
    "    print(f\"Model achieves {max(val_accs)*100:.1f}% accuracy - WEAK VISUAL SIGNAL\")\n",
    "    print(\"Some signal exists but it's noisy. May need more data or augmentation.\")\n",
    "else:\n",
    "    print(f\"Model achieves {max(val_accs)*100:.1f}% accuracy - NO CLEAR VISUAL SIGNAL\")\n",
    "    print(\"The visual frames alone don't predict dodge timing well.\")\n",
    "    print(\"Need to rely more on state features (NPC animation, positions).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
